import torch
import numpy as np
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import pickle
import os
import time

# ADDING CURRENT FOLDER TO THE PATH OF PACKAGES
import sys
sys.path.append(os.getcwd())
from tools.diffusion_model import ConditionalDiffusionModel
from tools.OCP_solving_cpin import solve_DOC

# Parameters
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
TIMESTEPS = 1000
N_SAMPLES = 50      # Number of samples generated by diffusion
MAX_LEN = 50        # Full length of the trajectory
W_DIM = 5           # Dimension of the cost weights
INPUT_CHANNELS = 4  # New parameter: q1, q2, dq1, dq2

# Generate ground truth weights (test data)
print("Generating Ground Truth trajectory...")

# w of bad case 2
w_true = np.array([0.73879914, 0.07483681, 0.1084752,  0.03661114, 0.0412777])
# w_true = np.random.rand(W_DIM)
# w_true = w_true / np.sum(w_true) # Normalize to sum to 1

print(f"True Weights: {w_true}")

# Train data for some comparison (Updated to match the new training set)
try:
    # Utilisation des fichiers du nouvel entrainement
    train_traj = np.load("data/array_results_angles_simplex_21_lim_joint_velocities_800.npy")
    w_train = np.load("data/array_w_simplex_21_lim_joint_velocities_800.npy")
except FileNotFoundError:
    print("Warning: New training data files not found. Trying fallback to old filenames...")
    train_traj = np.load("data/array_results_angles_10000.npy")
    w_train = np.load("data/array_w_10000.npy")


try:
    # Generating the ground truth trajectory (q1, q2) AND velocities (dq1, dq2)
    # NOTE: We now capture the second return value (velocities)
    traj_true_q, traj_true_dq = solve_DOC(w_true, x_fin=-1.0, q_init=np.array([0, np.pi/4]))
    
    # traj_true_q Shape: (50, 2)
    # traj_true_dq Shape: (50, 2)
except Exception as e:
    print(f"Error solving OCP for ground truth: {e}")
    exit()

# Comparison logic (based on angles q only)
distance_array_to_ground_truth = ((train_traj - traj_true_q)**2).mean(axis=(1,2))
closest_traj_to_ground_truth = np.argmin(distance_array_to_ground_truth)

closest_traj = train_traj[closest_traj_to_ground_truth]

# Load Model
# Initialize with input_channels=4
model = ConditionalDiffusionModel(w_dim=W_DIM, input_channels=INPUT_CHANNELS).to(DEVICE)

# Load the trained weights
model_path = "diffusion_model.pth" # Or "checkpoints/diffusion_model_final.pth"
if os.path.exists(model_path):
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    print(f"Loaded model from {model_path}")
else:
    print(f"Error: Model file '{model_path}' not found.")
    exit()

model.eval()

# Pre-compute diffusion schedule
beta = torch.linspace(1e-4, 0.02, TIMESTEPS).to(DEVICE)
alpha = 1. - beta
alpha_hat = torch.cumprod(alpha, dim=0)

# Diffusion sampling function
def sample_diffusion(model, condition_trajectory, n_samples):
    """
    Infers weights given a condition trajectory using the diffusion model.
    """
    model.eval()
    with torch.no_grad():
        # Replicate condition for the batch size
        cond_repeated = condition_trajectory.repeat(n_samples, 1, 1)
        
        # Start from pure Gaussian noise
        w_current = torch.randn(n_samples, W_DIM).to(DEVICE)

        # Denoising loop
        for i in reversed(range(TIMESTEPS)):
            t = torch.full((n_samples,), i, device=DEVICE, dtype=torch.long)
            predicted_noise = model(w_current, t, cond_repeated)

            alpha_t = alpha[i]
            alpha_hat_t = alpha_hat[i]
            beta_t = beta[i]

            if i > 0:
                noise = torch.randn_like(w_current)
            else:
                noise = torch.zeros_like(w_current)

            # Reverse diffusion step
            w_current = (1 / torch.sqrt(alpha_t)) * (
                w_current - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * predicted_noise
            ) + torch.sqrt(beta_t) * noise

    return w_current

# Prepare Data for Inference
# We use the full length 50
observation_length = MAX_LEN 

# 1. Get Angles and Velocities
q_input = traj_true_q[:observation_length]   # (50, 2)
dq_input = traj_true_dq[:observation_length] # (50, 2)

# 2. Concatenate along feature dimension -> (50, 4)
combined = np.concatenate([q_input, dq_input], axis=1)

# 3. Convert to Tensor and Transpose -> (1, 4, 50)
traj_tensor = torch.FloatTensor(combined).unsqueeze(0).transpose(1, 2).to(DEVICE)

# Run Inference
t_start = time.time()
print("Running diffusion inference...")
generated_w_normalized = sample_diffusion(model, traj_tensor, N_SAMPLES)
t_end = time.time()
print(f"Inference time: {t_end - t_start:.4f}s")

# Use generated weights directly (no scaler)
generated_w = generated_w_normalized

# Calculate the MEAN predicted weight
w_pred_mean = generated_w.detach().cpu().numpy().mean(axis=0)

print(f"Predicted Mean Weights: {w_pred_mean}")

# Reconstruct Trajectory
print("Solving OCP with predicted weights to reconstruct trajectory...")
try:
    # We only need the angles (first return) for plotting
    traj_reconstructed, _ = solve_DOC(w_pred_mean, x_fin=-1.0, q_init=np.array([0, np.pi/4]))
except Exception as e:
    print(f"Error solving OCP for reconstruction: {e}")
    traj_reconstructed = np.zeros_like(traj_true_q)

# Plotting Results (Separated)
fig, (ax_w, ax_q1, ax_q2) = plt.subplots(1, 3, figsize=(18, 6))

# Computing the closest trajectory of the dataset (based on angles)
distance_array_to_reconstructed = ((train_traj - traj_reconstructed)**2).mean(axis=(1,2))
closest_traj_to_reconstructed_index = np.argmin(distance_array_to_reconstructed)

# Plot 1: weights comparison
indices = np.arange(W_DIM)
width = 0.2
ax_w.bar(indices - 3*width/2, w_true, width, label='True Weights', color='black', alpha=0.7)
ax_w.bar(indices - width/2, w_pred_mean, width, label='Predicted (Mean)', color='orange', alpha=0.7)
ax_w.bar(indices + width/2, w_train[closest_traj_to_reconstructed_index], width, label='w closest to rec', color='red', alpha=0.7)
ax_w.bar(indices + 3*width/2, w_train[closest_traj_to_ground_truth], width, label='w closest to true', color='green', alpha=0.7)
ax_w.set_ylabel('Weight Value')
ax_w.set_title('Weights Comparison')
ax_w.set_xticks(indices)
ax_w.set_xticklabels([f'w{i+1}' for i in indices])
ax_w.legend(fontsize='small')
ax_w.grid(True, linestyle='--', alpha=0.3)

# RMSE Calculation
traj_true_deg = np.degrees(traj_true_q)
traj_rec_deg = np.degrees(traj_reconstructed)

rmse_q1 = np.sqrt(np.mean((traj_true_deg[:, 0] - traj_rec_deg[:, 0])**2))
rmse_q2 = np.sqrt(np.mean((traj_true_deg[:, 1] - traj_rec_deg[:, 1])**2))

# Plot 2: q1
ax_q1.plot(np.degrees(traj_true_q[:, 0]), 'k--', linewidth=2, label='q1 True')
ax_q1.plot(np.degrees(traj_reconstructed[:, 0]), 'b-', linewidth=2, alpha=0.8, label='q1 Reconstructed')
ax_q1.plot(np.degrees(train_traj[closest_traj_to_reconstructed_index][:, 0]), 'c:', linewidth=2, alpha=0.8, label='q1 closest (rec)')
ax_q1.plot(np.degrees(train_traj[closest_traj_to_ground_truth][:, 0]), 'm:', linewidth=2, alpha=0.8, label='q1 closest (true)')
ax_q1.set_title('Joint Angle q1')
ax_q1.set_xlabel('Time Step')
ax_q1.set_ylabel('Angle (deg)')
ax_q1.legend(fontsize='small')
ax_q1.grid(True, linestyle='--', alpha=0.3)

ax_q1.text(0.95, 0.05, f'RMSE: {rmse_q1:.2f}°', 
           transform=ax_q1.transAxes, 
           horizontalalignment='right', 
           verticalalignment='bottom',
           fontsize=12,
           bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="black", alpha=0.8))

# Plot 3: q2
ax_q2.plot(np.degrees(traj_true_q[:, 1]), 'k--', linewidth=2, label='q2 True')
ax_q2.plot(np.degrees(traj_reconstructed[:, 1]), 'r-', linewidth=2, alpha=0.8, label='q2 Reconstructed')
ax_q2.plot(np.degrees(train_traj[closest_traj_to_reconstructed_index][:, 1]), 'y:', linewidth=2, alpha=0.8, label='q2 closest (rec)')
ax_q2.plot(np.degrees(train_traj[closest_traj_to_ground_truth][:, 1]), 'm:', linewidth=2, alpha=0.8, label='q2 closest (true)')
ax_q2.set_title('Joint Angle q2')
ax_q2.set_xlabel('Time Step')
ax_q2.set_ylabel('Angle (deg)')
ax_q2.legend(fontsize='small')
ax_q2.grid(True, linestyle='--', alpha=0.3)

ax_q2.text(0.95, 0.05, f'RMSE: {rmse_q2:.2f}°', 
           transform=ax_q2.transAxes, 
           horizontalalignment='right', 
           verticalalignment='bottom',
           fontsize=12,
           bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="black", alpha=0.8))

plt.tight_layout()
plt.show()

# Save the figure
fig.savefig("reconstruction_separated_rmse.png")
print("Comparison plot saved as 'reconstruction_separated_rmse.png'")

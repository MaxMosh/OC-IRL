import torch
import numpy as np
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import pickle
import os
import time

# ADDING CURRENT FOLDER TO THE PATH OF PACKAGES
import sys
sys.path.append(os.getcwd())
# Assurez-vous d'importer la bonne version du modèle (Transformer ou celle avec input_channels=4)
from tools.diffusion_model_with_angular_velocities import ConditionalDiffusionModel
from tools.OCP_solving_cpin_new import solve_DOC

# Parameters
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
TIMESTEPS = 1000
N_SAMPLES = 50      # Number of samples generated by diffusion
MAX_LEN = 50        # Full length of the trajectory
W_DIM = 5           # Dimension of the cost weights
INPUT_CHANNELS = 4  # q1, q2, dq1, dq2

# Generate ground truth weights (test data)
print("Generating Ground Truth trajectory...")

w_true = np.array([0.73879914, 0.07483681, 0.1084752,  0.03661114, 0.0412777])
# w_true = np.array([0.21096545, 0.21082298, 0.27917708, 0.02229175, 0.27674274])
# w_true = np.array([0.23716818, 0.35012362, 0.10836774, 0.24728272, 0.05705774])


# w_true = np.random.rand(W_DIM)
# w_true = w_true / np.sum(w_true) # Normalize to sum to 1

print(f"True Weights: {w_true}")

# Train data for comparison
try:
    train_traj = np.load("data/array_results_angles_simplex_21_lim_joint_velocities_800.npy")
    train_velocities = np.load("data/array_results_angular_velocities_simplex_21_lim_joint_velocities_800.npy")
    w_train = np.load("data/array_w_simplex_21_lim_joint_velocities_800.npy")
except FileNotFoundError:
    print("Warning: New training data files not found. Check paths.")
    # Fallback ou exit si nécessaire
    exit()

try:
    # Generating the ground truth trajectory
    traj_true_q, traj_true_dq = solve_DOC(w_true, x_fin = 1.9, q_init = [-np.pi/2, np.pi/2])
except Exception as e:
    print(f"Error solving OCP for ground truth: {e}")
    exit()

# Comparison logic (based on angles q only)
distance_array_to_ground_truth = ((train_traj - traj_true_q)**2).mean(axis=(1,2))
closest_traj_to_ground_truth = np.argmin(distance_array_to_ground_truth)

# --- CHANGEMENT 1 : Chargement du Scaler ---
print("Loading model and scaler...")
scaler_path = 'scaler_w.pkl'
if os.path.exists(scaler_path):
    with open(scaler_path, 'rb') as f:
        scaler_w = pickle.load(f)
    print(f"Loaded scaler from {scaler_path}")
else:
    print(f"Error: Scaler file '{scaler_path}' not found. Did you run train.py with scaler enabled?")
    exit()

# Load Model
model = ConditionalDiffusionModel(w_dim=W_DIM, input_channels=INPUT_CHANNELS).to(DEVICE)

# model_path = "checkpoints/diffusion_model_final.pth"
model_path = "checkpoints/diffusion_model_final_with_scaler.pth"

if os.path.exists(model_path):
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    print(f"Loaded model from {model_path}")
else:
    print(f"Error: Model file '{model_path}' not found.")
    exit()

model.eval()

# Pre-compute diffusion schedule
beta = torch.linspace(1e-4, 0.02, TIMESTEPS).to(DEVICE)
alpha = 1. - beta
alpha_hat = torch.cumprod(alpha, dim=0)

def sample_diffusion(model, condition_trajectory, n_samples):
    model.eval()
    with torch.no_grad():
        cond_repeated = condition_trajectory.repeat(n_samples, 1, 1)
        w_current = torch.randn(n_samples, W_DIM).to(DEVICE)

        for i in reversed(range(TIMESTEPS)):
            t = torch.full((n_samples,), i, device=DEVICE, dtype=torch.long)
            predicted_noise = model(w_current, t, cond_repeated)

            alpha_t = alpha[i]
            alpha_hat_t = alpha_hat[i]
            beta_t = beta[i]

            if i > 0:
                noise = torch.randn_like(w_current)
            else:
                noise = torch.zeros_like(w_current)

            w_current = (1 / torch.sqrt(alpha_t)) * (
                w_current - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * predicted_noise
            ) + torch.sqrt(beta_t) * noise

    return w_current

# Prepare Data for Inference
observation_length = MAX_LEN 
traj_true_q = train_traj[closest_traj_to_ground_truth]              # MODIF: test with train data
# print(f"SHAPPE: {traj_true_q.shape}")
# print(f"SHAPPE: {closest_traj_to_ground_truth.shape}")
q_input = traj_true_q[:observation_length]   # (50, 2)
dq_input = traj_true_dq[:observation_length] # (50, 2)

combined = np.concatenate([q_input, dq_input], axis=1)
traj_tensor = torch.FloatTensor(combined).unsqueeze(0).transpose(1, 2).to(DEVICE)

# Run Inference
t_start = time.time()
print("Running diffusion inference...")
generated_w_normalized = sample_diffusion(model, traj_tensor, N_SAMPLES)
t_end = time.time()
print(f"Inference time: {t_end - t_start:.4f}s")

# --- CHANGEMENT 2 : Application de l'inverse transform ---
# On passe des poids normalisés (sortie du modèle) aux poids réels
generated_w = scaler_w.inverse_transform(generated_w_normalized.cpu().numpy())

# Calculate the MEAN predicted weight
w_pred_mean = np.mean(generated_w, axis=0)
w_pred_mean = w_pred_mean / np.sum(w_pred_mean) # Normalize to sum to 1

# Optional: Re-normalize to simplex (sum=1) if your problem strictly requires it,
# although the scaler should bring it close to the original distribution.
# if np.sum(w_pred_mean) > 0:
#     w_pred_mean = w_pred_mean / np.sum(w_pred_mean)

print(f"Predicted Mean Weights: {w_pred_mean}")

# Reconstruct Trajectory
print("Solving OCP with predicted weights to reconstruct trajectory...")
try:
    traj_reconstructed, _ = solve_DOC(w_pred_mean, x_fin = 1.9, q_init = [-np.pi/2, np.pi/2])
except Exception as e:
    print(f"Error solving OCP for reconstruction: {e}")
    traj_reconstructed = np.zeros_like(traj_true_q)

# Plotting Results
fig, (ax_w, ax_q1, ax_q2) = plt.subplots(1, 3, figsize=(18, 6))

distance_array_to_reconstructed = ((train_traj - traj_reconstructed)**2).mean(axis=(1,2))
closest_traj_to_reconstructed_index = np.argmin(distance_array_to_reconstructed)

# Plot 1: weights comparison
indices = np.arange(W_DIM)
width = 0.2
ax_w.bar(indices - 3*width/2, w_true, width, label='True Weights', color='black', alpha=0.7)
ax_w.bar(indices - width/2, w_pred_mean, width, label='Predicted (Mean)', color='orange', alpha=0.7)
ax_w.bar(indices + width/2, w_train[closest_traj_to_reconstructed_index], width, label='w closest to rec', color='red', alpha=0.7)
ax_w.bar(indices + 3*width/2, w_train[closest_traj_to_ground_truth], width, label='w closest to true', color='green', alpha=0.7)
ax_w.set_ylabel('Weight Value')
ax_w.set_title('Weights Comparison')
ax_w.set_xticks(indices)
ax_w.set_xticklabels([f'w{i+1}' for i in indices])
ax_w.legend(fontsize='small')
ax_w.grid(True, linestyle='--', alpha=0.3)

# RMSE Calculation
traj_true_deg = np.degrees(traj_true_q)
traj_rec_deg = np.degrees(traj_reconstructed)

rmse_q1 = np.sqrt(np.mean((traj_true_deg[:, 0] - traj_rec_deg[:, 0])**2))
rmse_q2 = np.sqrt(np.mean((traj_true_deg[:, 1] - traj_rec_deg[:, 1])**2))

# Plot 2: q1
ax_q1.plot(np.degrees(traj_true_q[:, 0]), 'k--', linewidth=2, label='q1 True')
ax_q1.plot(np.degrees(traj_reconstructed[:, 0]), 'b-', linewidth=2, alpha=0.8, label='q1 Reconstructed')
ax_q1.plot(np.degrees(train_traj[closest_traj_to_reconstructed_index][:, 0]), 'c:', linewidth=2, alpha=0.8, label='q1 closest (rec)')
ax_q1.plot(np.degrees(train_traj[closest_traj_to_ground_truth][:, 0]), 'm:', linewidth=2, alpha=0.8, label='q1 closest (true)')
ax_q1.set_title('Joint Angle q1')
ax_q1.set_xlabel('Time Step')
ax_q1.set_ylabel('Angle (deg)')
ax_q1.legend(fontsize='small')
ax_q1.grid(True, linestyle='--', alpha=0.3)
ax_q1.text(0.95, 0.05, f'RMSE: {rmse_q1:.2f}°', transform=ax_q1.transAxes, ha='right', va='bottom', bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.8))

# Plot 3: q2
ax_q2.plot(np.degrees(traj_true_q[:, 1]), 'k--', linewidth=2, label='q2 True')
ax_q2.plot(np.degrees(traj_reconstructed[:, 1]), 'r-', linewidth=2, alpha=0.8, label='q2 Reconstructed')
ax_q2.plot(np.degrees(train_traj[closest_traj_to_reconstructed_index][:, 1]), 'y:', linewidth=2, alpha=0.8, label='q2 closest (rec)')
ax_q2.plot(np.degrees(train_traj[closest_traj_to_ground_truth][:, 1]), 'm:', linewidth=2, alpha=0.8, label='q2 closest (true)')
ax_q2.set_title('Joint Angle q2')
ax_q2.set_xlabel('Time Step')
ax_q2.set_ylabel('Angle (deg)')
ax_q2.legend(fontsize='small')
ax_q2.grid(True, linestyle='--', alpha=0.3)
ax_q2.text(0.95, 0.05, f'RMSE: {rmse_q2:.2f}°', transform=ax_q2.transAxes, ha='right', va='bottom', bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.8))

plt.tight_layout()
plt.show()

fig.savefig("reconstruction_separated_rmse_with_scaler.png")
print("Comparison plot saved as 'reconstruction_separated_rmse_with_scaler.png'")